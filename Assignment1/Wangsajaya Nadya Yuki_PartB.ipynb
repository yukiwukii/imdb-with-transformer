{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jnRX6LUnqBpw"
   },
   "source": [
    "CS4001/4042 Assignment 1\n",
    "---\n",
    "Part B, Q1 (15 marks)\n",
    "---\n",
    "\n",
    "Real world datasets often have a mix of numeric and categorical features – this dataset is one example. To build models on such data, categorical features have to be encoded or embedded.\n",
    "\n",
    "PyTorch Tabular is a library that makes it very convenient to build neural networks for tabular data. It is built on top of PyTorch Lightning, which abstracts away boilerplate model training code and makes it easy to integrate other tools, e.g. TensorBoard for experiment tracking.\n",
    "\n",
    "For questions B1 and B2, the following features should be used:   \n",
    "- **Numeric / Continuous** features: dist_to_nearest_stn, dist_to_dhoby, degree_centrality, eigenvector_centrality, remaining_lease_years, floor_area_sqm\n",
    "- **Categorical** features: month, town, flat_model_type, storey_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "id": "jA67PbIY3PnH"
   },
   "outputs": [],
   "source": [
    "# pip install \"pytorch_tabular[extra]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip uninstall \"torch\" -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch==2.5.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Jr6P3U7w3NVl"
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "import os\n",
    "\n",
    "import random\n",
    "random.seed(SEED)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig\n",
    "from pytorch_tabular.config import (\n",
    "    DataConfig,\n",
    "    OptimizerConfig,\n",
    "    TrainerConfig,\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zGyEWcVlqKTz"
   },
   "source": [
    "> Divide the dataset (‘hdb_price_prediction.csv’) into train and test sets by using entries from year 2020 and before as training data, and year 2021 as test data (validation set is not required).\n",
    "**Do not** use data from year 2022 and year 2023.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "hoCPcOWupw5Y"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('hdb_price_prediction.csv')\n",
    "df_train = df[df['year'] <= 2020]\n",
    "df_test = df[df['year'] == 2021] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sebMgSuzqPe7"
   },
   "source": [
    "> Refer to the documentation of **PyTorch Tabular** and perform the following tasks: https://pytorch-tabular.readthedocs.io/en/latest/#usage\n",
    "- Use **[DataConfig](https://pytorch-tabular.readthedocs.io/en/latest/data/)** to define the target variable, as well as the names of the continuous and categorical variables.\n",
    "- Use **[TrainerConfig](https://pytorch-tabular.readthedocs.io/en/latest/training/)** to automatically tune the learning rate. Set batch_size to be 1024 and set max_epoch as 50.\n",
    "- Use **[CategoryEmbeddingModelConfig](https://pytorch-tabular.readthedocs.io/en/latest/models/#category-embedding-model)** to create a feedforward neural network with 1 hidden layer containing 50 neurons.\n",
    "- Use **[OptimizerConfig](https://pytorch-tabular.readthedocs.io/en/latest/optimizer/)** to choose Adam optimiser. There is no need to set the learning rate (since it will be tuned automatically) nor scheduler.\n",
    "- Use **[TabularModel](https://pytorch-tabular.readthedocs.io/en/latest/tabular_model/)** to initialise the model and put all the configs together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "ZZWAYdNhqPzh"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">08:04:42</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">840</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m08:04:42\u001b[0m,\u001b[1;36m840\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_config = DataConfig(\n",
    "    target=[\"resale_price\"],\n",
    "    continuous_cols=[\"dist_to_nearest_stn\", \"dist_to_dhoby\", \"degree_centrality\",\n",
    "                     \"eigenvector_centrality\", \"remaining_lease_years\", \"floor_area_sqm\"],\n",
    "    categorical_cols=[\"month\", \"town\", \"flat_model_type\", \"storey_range\"]\n",
    ")\n",
    "\n",
    "trainer_config = TrainerConfig(batch_size=1024, max_epochs=50, accelerator=\"auto\", auto_lr_find=True)\n",
    "model_config = CategoryEmbeddingModelConfig(task=\"regression\", layers='50', seed=SEED, metrics=['mean_squared_error','r2_score'])\n",
    "optimizer_config = OptimizerConfig(optimizer='Adam')\n",
    "\n",
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-2UXPKq0qWQG"
   },
   "source": [
    "> Report the test RMSE error and the test R2 value that you obtained.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "zmE9Bc7Nqadi"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">08:04:44</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">829</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m08:04:44\u001b[0m,\u001b[1;36m829\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">08:04:44</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">863</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m08:04:44\u001b[0m,\u001b[1;36m863\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">08:04:44</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">939</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: CategoryEmbeddingModel \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m08:04:44\u001b[0m,\u001b[1;36m939\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: CategoryEmbeddingModel \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">08:04:44</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">959</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m08:04:44\u001b[0m,\u001b[1;36m959\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">08:04:45</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">012</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">656</span><span style=\"font-weight: bold\">}</span> - INFO - Auto LR Find Started                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m08:04:45\u001b[0m,\u001b[1;36m012\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m656\u001b[0m\u001b[1m}\u001b[0m - INFO - Auto LR Find Started                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuki/Library/Mobile Documents/com~apple~CloudDocs/NTU/Y2S2/SC4001/Projects/Assignment1/.venv/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/yuki/Library/Mobile Documents/com~apple~CloudDocs/NTU/Y2S2/SC4001/Projects/Assignment1/saved_models exists and is not empty.\n",
      "/Users/yuki/Library/Mobile Documents/com~apple~CloudDocs/NTU/Y2S2/SC4001/Projects/Assignment1/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n",
      "/Users/yuki/Library/Mobile Documents/com~apple~CloudDocs/NTU/Y2S2/SC4001/Projects/Assignment1/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1b6c2f6a352403da8ed281aea3c8a4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 0.5754399373371567\n",
      "Restoring states from the checkpoint path at /Users/yuki/Library/Mobile Documents/com~apple~CloudDocs/NTU/Y2S2/SC4001/Projects/Assignment1/.lr_find_d3edfeab-7f3b-4886-ba49-4da914f39228.ckpt\n",
      "Restored all states from the checkpoint at /Users/yuki/Library/Mobile Documents/com~apple~CloudDocs/NTU/Y2S2/SC4001/Projects/Assignment1/.lr_find_d3edfeab-7f3b-4886-ba49-4da914f39228.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">08:04:47</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">922</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">669</span><span style=\"font-weight: bold\">}</span> - INFO - Suggested LR: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5754399373371567</span>. For plot  \n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m08:04:47\u001b[0m,\u001b[1;36m922\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m669\u001b[0m\u001b[1m}\u001b[0m - INFO - Suggested LR: \u001b[1;36m0.5754399373371567\u001b[0m. For plot  \n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">08:04:47</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">924</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m08:04:47\u001b[0m,\u001b[1;36m924\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ CategoryEmbeddingBackbone │  3.0 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer          │  1.6 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ head             │ LinearHead                │     51 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss                   │      0 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ CategoryEmbeddingBackbone │  3.0 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer          │  1.6 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ head             │ LinearHead                │     51 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss                   │      0 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 4.6 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 4.6 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 16                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 4.6 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 4.6 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 16                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c582038b1f84cb9a61b841772824aa6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">08:05:03</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">388</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m08:05:03\u001b[0m,\u001b[1;36m388\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">08:05:03</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">389</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m08:05:03\u001b[0m,\u001b[1;36m389\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<pytorch_lightning.trainer.trainer.Trainer at 0x333e0e1d0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabular_model.fit(train=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = tabular_model.predict(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "878350d81f1043fcb2c3f12a3622a0d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuki/Library/Mobile Documents/com~apple~CloudDocs/NTU/Y2S2/SC4001/Projects/Assignment1/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       4421792256.0        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test_mean_squared_error  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       4421792256.0        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_r2_score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7447481155395508     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      4421792256.0       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m test_mean_squared_error \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      4421792256.0       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_r2_score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7447481155395508    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 66497\n",
      "R2 score: 0.7447\n"
     ]
    }
   ],
   "source": [
    "test_results = tabular_model.evaluate(df_test)\n",
    "print(f\"RMSE: {np.sqrt(test_results[0]['test_mean_squared_error']):.0f}\")\n",
    "print(f\"R2 score: {test_results[0]['test_r2_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NEJhRU18qX22"
   },
   "source": [
    "> Print out the corresponding rows in the dataframe for the top 25 test samples with the largest errors. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "5ma5K9vKqZEq"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>town</th>\n",
       "      <th>full_address</th>\n",
       "      <th>nearest_stn</th>\n",
       "      <th>dist_to_nearest_stn</th>\n",
       "      <th>dist_to_dhoby</th>\n",
       "      <th>degree_centrality</th>\n",
       "      <th>eigenvector_centrality</th>\n",
       "      <th>flat_model_type</th>\n",
       "      <th>remaining_lease_years</th>\n",
       "      <th>floor_area_sqm</th>\n",
       "      <th>storey_range</th>\n",
       "      <th>resale_price</th>\n",
       "      <th>prediction</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>92405</th>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>BUKIT MERAH</td>\n",
       "      <td>46 SENG POH ROAD</td>\n",
       "      <td>Tiong Bahru</td>\n",
       "      <td>0.581977</td>\n",
       "      <td>2.309477</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.047782</td>\n",
       "      <td>3 ROOM, Standard</td>\n",
       "      <td>50.166667</td>\n",
       "      <td>88.0</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>780000.0</td>\n",
       "      <td>3.983550e+05</td>\n",
       "      <td>381644.96875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90957</th>\n",
       "      <td>6</td>\n",
       "      <td>2021</td>\n",
       "      <td>BUKIT BATOK</td>\n",
       "      <td>288A BUKIT BATOK STREET 25</td>\n",
       "      <td>Bukit Batok</td>\n",
       "      <td>1.292540</td>\n",
       "      <td>10.763777</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>EXECUTIVE, Apartment</td>\n",
       "      <td>75.583333</td>\n",
       "      <td>144.0</td>\n",
       "      <td>10 TO 12</td>\n",
       "      <td>968000.0</td>\n",
       "      <td>6.130271e+05</td>\n",
       "      <td>354972.87500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90601</th>\n",
       "      <td>12</td>\n",
       "      <td>2021</td>\n",
       "      <td>BISHAN</td>\n",
       "      <td>251 BISHAN STREET 22</td>\n",
       "      <td>Ang Mo Kio</td>\n",
       "      <td>1.081018</td>\n",
       "      <td>6.939944</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.006243</td>\n",
       "      <td>5 ROOM, Improved</td>\n",
       "      <td>69.750000</td>\n",
       "      <td>126.0</td>\n",
       "      <td>04 TO 06</td>\n",
       "      <td>935000.0</td>\n",
       "      <td>6.218501e+05</td>\n",
       "      <td>313149.87500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90382</th>\n",
       "      <td>7</td>\n",
       "      <td>2021</td>\n",
       "      <td>BISHAN</td>\n",
       "      <td>251 BISHAN STREET 22</td>\n",
       "      <td>Ang Mo Kio</td>\n",
       "      <td>1.081018</td>\n",
       "      <td>6.939944</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.006243</td>\n",
       "      <td>5 ROOM, Improved</td>\n",
       "      <td>70.166667</td>\n",
       "      <td>121.0</td>\n",
       "      <td>10 TO 12</td>\n",
       "      <td>945000.0</td>\n",
       "      <td>6.372696e+05</td>\n",
       "      <td>307730.43750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92533</th>\n",
       "      <td>12</td>\n",
       "      <td>2021</td>\n",
       "      <td>BUKIT MERAH</td>\n",
       "      <td>2C BOON TIONG ROAD</td>\n",
       "      <td>Tiong Bahru</td>\n",
       "      <td>0.656363</td>\n",
       "      <td>1.982722</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.047782</td>\n",
       "      <td>5 ROOM, Improved</td>\n",
       "      <td>78.083333</td>\n",
       "      <td>115.0</td>\n",
       "      <td>28 TO 30</td>\n",
       "      <td>1130000.0</td>\n",
       "      <td>8.252847e+05</td>\n",
       "      <td>304715.31250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90608</th>\n",
       "      <td>12</td>\n",
       "      <td>2021</td>\n",
       "      <td>BISHAN</td>\n",
       "      <td>273B BISHAN STREET 24</td>\n",
       "      <td>Bishan</td>\n",
       "      <td>0.776182</td>\n",
       "      <td>6.297489</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.015854</td>\n",
       "      <td>5 ROOM, DBSS</td>\n",
       "      <td>88.833333</td>\n",
       "      <td>120.0</td>\n",
       "      <td>37 TO 39</td>\n",
       "      <td>1360000.0</td>\n",
       "      <td>1.067169e+06</td>\n",
       "      <td>292831.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92340</th>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "      <td>BUKIT MERAH</td>\n",
       "      <td>56 HAVELOCK ROAD</td>\n",
       "      <td>Tiong Bahru</td>\n",
       "      <td>0.451387</td>\n",
       "      <td>2.128424</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.047782</td>\n",
       "      <td>5 ROOM, Improved</td>\n",
       "      <td>90.750000</td>\n",
       "      <td>114.0</td>\n",
       "      <td>34 TO 36</td>\n",
       "      <td>1245000.0</td>\n",
       "      <td>9.555907e+05</td>\n",
       "      <td>289409.31250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91871</th>\n",
       "      <td>6</td>\n",
       "      <td>2021</td>\n",
       "      <td>BUKIT MERAH</td>\n",
       "      <td>17 TIONG BAHRU ROAD</td>\n",
       "      <td>Tiong Bahru</td>\n",
       "      <td>0.693391</td>\n",
       "      <td>2.058774</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.047782</td>\n",
       "      <td>3 ROOM, Standard</td>\n",
       "      <td>50.583333</td>\n",
       "      <td>88.0</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>680888.0</td>\n",
       "      <td>3.917240e+05</td>\n",
       "      <td>289163.96875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89770</th>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "      <td>BEDOK</td>\n",
       "      <td>103 LENGKONG TIGA</td>\n",
       "      <td>Kembangan</td>\n",
       "      <td>0.622824</td>\n",
       "      <td>7.791966</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.002799</td>\n",
       "      <td>5 ROOM, Improved</td>\n",
       "      <td>66.333333</td>\n",
       "      <td>126.0</td>\n",
       "      <td>10 TO 12</td>\n",
       "      <td>868000.0</td>\n",
       "      <td>5.796232e+05</td>\n",
       "      <td>288376.75000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92442</th>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>BUKIT MERAH</td>\n",
       "      <td>127D KIM TIAN ROAD</td>\n",
       "      <td>Tiong Bahru</td>\n",
       "      <td>0.686789</td>\n",
       "      <td>2.664024</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.047782</td>\n",
       "      <td>5 ROOM, Improved</td>\n",
       "      <td>90.333333</td>\n",
       "      <td>113.0</td>\n",
       "      <td>16 TO 18</td>\n",
       "      <td>1165000.0</td>\n",
       "      <td>8.769507e+05</td>\n",
       "      <td>288049.31250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92504</th>\n",
       "      <td>12</td>\n",
       "      <td>2021</td>\n",
       "      <td>BUKIT MERAH</td>\n",
       "      <td>49 KIM PONG ROAD</td>\n",
       "      <td>Tiong Bahru</td>\n",
       "      <td>0.468378</td>\n",
       "      <td>2.365532</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.047782</td>\n",
       "      <td>3 ROOM, Standard</td>\n",
       "      <td>50.166667</td>\n",
       "      <td>88.0</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>695000.0</td>\n",
       "      <td>4.072437e+05</td>\n",
       "      <td>287756.31250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90600</th>\n",
       "      <td>12</td>\n",
       "      <td>2021</td>\n",
       "      <td>BISHAN</td>\n",
       "      <td>251 BISHAN STREET 22</td>\n",
       "      <td>Ang Mo Kio</td>\n",
       "      <td>1.081018</td>\n",
       "      <td>6.939944</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.006243</td>\n",
       "      <td>5 ROOM, Improved</td>\n",
       "      <td>69.666667</td>\n",
       "      <td>121.0</td>\n",
       "      <td>07 TO 09</td>\n",
       "      <td>920000.0</td>\n",
       "      <td>6.324519e+05</td>\n",
       "      <td>287548.12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88081</th>\n",
       "      <td>8</td>\n",
       "      <td>2021</td>\n",
       "      <td>ANG MO KIO</td>\n",
       "      <td>310A ANG MO KIO AVENUE 1</td>\n",
       "      <td>Ang Mo Kio</td>\n",
       "      <td>0.860056</td>\n",
       "      <td>7.263401</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.006243</td>\n",
       "      <td>5 ROOM, Improved</td>\n",
       "      <td>90.166667</td>\n",
       "      <td>121.0</td>\n",
       "      <td>28 TO 30</td>\n",
       "      <td>1100000.0</td>\n",
       "      <td>8.136795e+05</td>\n",
       "      <td>286320.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92299</th>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "      <td>BUKIT MERAH</td>\n",
       "      <td>36 MOH GUAN TERRACE</td>\n",
       "      <td>Tiong Bahru</td>\n",
       "      <td>0.490926</td>\n",
       "      <td>2.278805</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.047782</td>\n",
       "      <td>3 ROOM, Standard</td>\n",
       "      <td>50.333333</td>\n",
       "      <td>88.0</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>690000.0</td>\n",
       "      <td>4.040589e+05</td>\n",
       "      <td>285941.06250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105702</th>\n",
       "      <td>6</td>\n",
       "      <td>2021</td>\n",
       "      <td>QUEENSTOWN</td>\n",
       "      <td>150 MEI LING STREET</td>\n",
       "      <td>Queenstown</td>\n",
       "      <td>0.245207</td>\n",
       "      <td>4.709043</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.008342</td>\n",
       "      <td>EXECUTIVE, Apartment</td>\n",
       "      <td>73.416667</td>\n",
       "      <td>148.0</td>\n",
       "      <td>10 TO 12</td>\n",
       "      <td>1235000.0</td>\n",
       "      <td>9.508851e+05</td>\n",
       "      <td>284114.87500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93895</th>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>CENTRAL AREA</td>\n",
       "      <td>3 TANJONG PAGAR PLAZA</td>\n",
       "      <td>Tanjong Pagar</td>\n",
       "      <td>0.490378</td>\n",
       "      <td>2.630876</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.103876</td>\n",
       "      <td>5 ROOM, Adjoined flat</td>\n",
       "      <td>54.250000</td>\n",
       "      <td>139.0</td>\n",
       "      <td>07 TO 09</td>\n",
       "      <td>958000.0</td>\n",
       "      <td>6.745587e+05</td>\n",
       "      <td>283441.31250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93825</th>\n",
       "      <td>8</td>\n",
       "      <td>2021</td>\n",
       "      <td>CENTRAL AREA</td>\n",
       "      <td>4 TANJONG PAGAR PLAZA</td>\n",
       "      <td>Tanjong Pagar</td>\n",
       "      <td>0.451637</td>\n",
       "      <td>2.594828</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.103876</td>\n",
       "      <td>5 ROOM, Adjoined flat</td>\n",
       "      <td>54.583333</td>\n",
       "      <td>118.0</td>\n",
       "      <td>16 TO 18</td>\n",
       "      <td>938000.0</td>\n",
       "      <td>6.570492e+05</td>\n",
       "      <td>280950.75000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91694</th>\n",
       "      <td>4</td>\n",
       "      <td>2021</td>\n",
       "      <td>BUKIT MERAH</td>\n",
       "      <td>35 LIM LIAK STREET</td>\n",
       "      <td>Tiong Bahru</td>\n",
       "      <td>0.481551</td>\n",
       "      <td>2.262574</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.047782</td>\n",
       "      <td>3 ROOM, Standard</td>\n",
       "      <td>50.833333</td>\n",
       "      <td>88.0</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>680000.0</td>\n",
       "      <td>4.008262e+05</td>\n",
       "      <td>279173.81250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100836</th>\n",
       "      <td>6</td>\n",
       "      <td>2021</td>\n",
       "      <td>KALLANG/WHAMPOA</td>\n",
       "      <td>39 JALAN BAHAGIA</td>\n",
       "      <td>Boon Keng</td>\n",
       "      <td>0.998313</td>\n",
       "      <td>3.304953</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.053004</td>\n",
       "      <td>3 ROOM, Terrace</td>\n",
       "      <td>50.083333</td>\n",
       "      <td>210.0</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>1268000.0</td>\n",
       "      <td>9.892076e+05</td>\n",
       "      <td>278792.37500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112128</th>\n",
       "      <td>12</td>\n",
       "      <td>2021</td>\n",
       "      <td>TAMPINES</td>\n",
       "      <td>156 TAMPINES STREET 12</td>\n",
       "      <td>Tampines</td>\n",
       "      <td>0.370873</td>\n",
       "      <td>12.479752</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>EXECUTIVE, Maisonette</td>\n",
       "      <td>61.750000</td>\n",
       "      <td>148.0</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>998000.0</td>\n",
       "      <td>7.200508e+05</td>\n",
       "      <td>277949.25000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90521</th>\n",
       "      <td>10</td>\n",
       "      <td>2021</td>\n",
       "      <td>BISHAN</td>\n",
       "      <td>237 BISHAN STREET 22</td>\n",
       "      <td>Bishan</td>\n",
       "      <td>0.947205</td>\n",
       "      <td>6.663943</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.015854</td>\n",
       "      <td>5 ROOM, Improved</td>\n",
       "      <td>69.583333</td>\n",
       "      <td>121.0</td>\n",
       "      <td>07 TO 09</td>\n",
       "      <td>988000.0</td>\n",
       "      <td>7.135319e+05</td>\n",
       "      <td>274468.12500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101237</th>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>KALLANG/WHAMPOA</td>\n",
       "      <td>8 BOON KENG ROAD</td>\n",
       "      <td>Bendemeer</td>\n",
       "      <td>0.352251</td>\n",
       "      <td>2.587444</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.004414</td>\n",
       "      <td>5 ROOM, DBSS</td>\n",
       "      <td>88.250000</td>\n",
       "      <td>119.0</td>\n",
       "      <td>40 TO 42</td>\n",
       "      <td>1268000.0</td>\n",
       "      <td>9.967523e+05</td>\n",
       "      <td>271247.68750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90432</th>\n",
       "      <td>8</td>\n",
       "      <td>2021</td>\n",
       "      <td>BISHAN</td>\n",
       "      <td>275A BISHAN STREET 24</td>\n",
       "      <td>Bishan</td>\n",
       "      <td>0.827889</td>\n",
       "      <td>6.370404</td>\n",
       "      <td>0.033613</td>\n",
       "      <td>0.015854</td>\n",
       "      <td>5 ROOM, DBSS</td>\n",
       "      <td>88.916667</td>\n",
       "      <td>120.0</td>\n",
       "      <td>25 TO 27</td>\n",
       "      <td>1280000.0</td>\n",
       "      <td>1.009172e+06</td>\n",
       "      <td>270828.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92379</th>\n",
       "      <td>11</td>\n",
       "      <td>2021</td>\n",
       "      <td>BUKIT MERAH</td>\n",
       "      <td>48 MOH GUAN TERRACE</td>\n",
       "      <td>Tiong Bahru</td>\n",
       "      <td>0.538563</td>\n",
       "      <td>2.345844</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.047782</td>\n",
       "      <td>3 ROOM, Standard</td>\n",
       "      <td>50.250000</td>\n",
       "      <td>77.0</td>\n",
       "      <td>04 TO 06</td>\n",
       "      <td>640000.0</td>\n",
       "      <td>3.695614e+05</td>\n",
       "      <td>270438.62500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92066</th>\n",
       "      <td>8</td>\n",
       "      <td>2021</td>\n",
       "      <td>BUKIT MERAH</td>\n",
       "      <td>48 MOH GUAN TERRACE</td>\n",
       "      <td>Tiong Bahru</td>\n",
       "      <td>0.538563</td>\n",
       "      <td>2.345844</td>\n",
       "      <td>0.016807</td>\n",
       "      <td>0.047782</td>\n",
       "      <td>3 ROOM, Standard</td>\n",
       "      <td>50.500000</td>\n",
       "      <td>77.0</td>\n",
       "      <td>01 TO 03</td>\n",
       "      <td>628000.0</td>\n",
       "      <td>3.577162e+05</td>\n",
       "      <td>270283.75000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        month  year             town                full_address  \\\n",
       "92405      11  2021      BUKIT MERAH            46 SENG POH ROAD   \n",
       "90957       6  2021      BUKIT BATOK  288A BUKIT BATOK STREET 25   \n",
       "90601      12  2021           BISHAN        251 BISHAN STREET 22   \n",
       "90382       7  2021           BISHAN        251 BISHAN STREET 22   \n",
       "92533      12  2021      BUKIT MERAH          2C BOON TIONG ROAD   \n",
       "90608      12  2021           BISHAN       273B BISHAN STREET 24   \n",
       "92340      10  2021      BUKIT MERAH            56 HAVELOCK ROAD   \n",
       "91871       6  2021      BUKIT MERAH         17 TIONG BAHRU ROAD   \n",
       "89770      10  2021            BEDOK           103 LENGKONG TIGA   \n",
       "92442      11  2021      BUKIT MERAH          127D KIM TIAN ROAD   \n",
       "92504      12  2021      BUKIT MERAH            49 KIM PONG ROAD   \n",
       "90600      12  2021           BISHAN        251 BISHAN STREET 22   \n",
       "88081       8  2021       ANG MO KIO    310A ANG MO KIO AVENUE 1   \n",
       "92299      10  2021      BUKIT MERAH         36 MOH GUAN TERRACE   \n",
       "105702      6  2021       QUEENSTOWN         150 MEI LING STREET   \n",
       "93895      11  2021     CENTRAL AREA       3 TANJONG PAGAR PLAZA   \n",
       "93825       8  2021     CENTRAL AREA       4 TANJONG PAGAR PLAZA   \n",
       "91694       4  2021      BUKIT MERAH          35 LIM LIAK STREET   \n",
       "100836      6  2021  KALLANG/WHAMPOA            39 JALAN BAHAGIA   \n",
       "112128     12  2021         TAMPINES      156 TAMPINES STREET 12   \n",
       "90521      10  2021           BISHAN        237 BISHAN STREET 22   \n",
       "101237     11  2021  KALLANG/WHAMPOA            8 BOON KENG ROAD   \n",
       "90432       8  2021           BISHAN       275A BISHAN STREET 24   \n",
       "92379      11  2021      BUKIT MERAH         48 MOH GUAN TERRACE   \n",
       "92066       8  2021      BUKIT MERAH         48 MOH GUAN TERRACE   \n",
       "\n",
       "          nearest_stn  dist_to_nearest_stn  dist_to_dhoby  degree_centrality  \\\n",
       "92405     Tiong Bahru             0.581977       2.309477           0.016807   \n",
       "90957     Bukit Batok             1.292540      10.763777           0.016807   \n",
       "90601      Ang Mo Kio             1.081018       6.939944           0.016807   \n",
       "90382      Ang Mo Kio             1.081018       6.939944           0.016807   \n",
       "92533     Tiong Bahru             0.656363       1.982722           0.016807   \n",
       "90608          Bishan             0.776182       6.297489           0.033613   \n",
       "92340     Tiong Bahru             0.451387       2.128424           0.016807   \n",
       "91871     Tiong Bahru             0.693391       2.058774           0.016807   \n",
       "89770       Kembangan             0.622824       7.791966           0.016807   \n",
       "92442     Tiong Bahru             0.686789       2.664024           0.016807   \n",
       "92504     Tiong Bahru             0.468378       2.365532           0.016807   \n",
       "90600      Ang Mo Kio             1.081018       6.939944           0.016807   \n",
       "88081      Ang Mo Kio             0.860056       7.263401           0.016807   \n",
       "92299     Tiong Bahru             0.490926       2.278805           0.016807   \n",
       "105702     Queenstown             0.245207       4.709043           0.016807   \n",
       "93895   Tanjong Pagar             0.490378       2.630876           0.016807   \n",
       "93825   Tanjong Pagar             0.451637       2.594828           0.016807   \n",
       "91694     Tiong Bahru             0.481551       2.262574           0.016807   \n",
       "100836      Boon Keng             0.998313       3.304953           0.016807   \n",
       "112128       Tampines             0.370873      12.479752           0.033613   \n",
       "90521          Bishan             0.947205       6.663943           0.033613   \n",
       "101237      Bendemeer             0.352251       2.587444           0.016807   \n",
       "90432          Bishan             0.827889       6.370404           0.033613   \n",
       "92379     Tiong Bahru             0.538563       2.345844           0.016807   \n",
       "92066     Tiong Bahru             0.538563       2.345844           0.016807   \n",
       "\n",
       "        eigenvector_centrality        flat_model_type  remaining_lease_years  \\\n",
       "92405                 0.047782       3 ROOM, Standard              50.166667   \n",
       "90957                 0.000217   EXECUTIVE, Apartment              75.583333   \n",
       "90601                 0.006243       5 ROOM, Improved              69.750000   \n",
       "90382                 0.006243       5 ROOM, Improved              70.166667   \n",
       "92533                 0.047782       5 ROOM, Improved              78.083333   \n",
       "90608                 0.015854           5 ROOM, DBSS              88.833333   \n",
       "92340                 0.047782       5 ROOM, Improved              90.750000   \n",
       "91871                 0.047782       3 ROOM, Standard              50.583333   \n",
       "89770                 0.002799       5 ROOM, Improved              66.333333   \n",
       "92442                 0.047782       5 ROOM, Improved              90.333333   \n",
       "92504                 0.047782       3 ROOM, Standard              50.166667   \n",
       "90600                 0.006243       5 ROOM, Improved              69.666667   \n",
       "88081                 0.006243       5 ROOM, Improved              90.166667   \n",
       "92299                 0.047782       3 ROOM, Standard              50.333333   \n",
       "105702                0.008342   EXECUTIVE, Apartment              73.416667   \n",
       "93895                 0.103876  5 ROOM, Adjoined flat              54.250000   \n",
       "93825                 0.103876  5 ROOM, Adjoined flat              54.583333   \n",
       "91694                 0.047782       3 ROOM, Standard              50.833333   \n",
       "100836                0.053004        3 ROOM, Terrace              50.083333   \n",
       "112128                0.000229  EXECUTIVE, Maisonette              61.750000   \n",
       "90521                 0.015854       5 ROOM, Improved              69.583333   \n",
       "101237                0.004414           5 ROOM, DBSS              88.250000   \n",
       "90432                 0.015854           5 ROOM, DBSS              88.916667   \n",
       "92379                 0.047782       3 ROOM, Standard              50.250000   \n",
       "92066                 0.047782       3 ROOM, Standard              50.500000   \n",
       "\n",
       "        floor_area_sqm storey_range  resale_price    prediction         error  \n",
       "92405             88.0     01 TO 03      780000.0  3.983550e+05  381644.96875  \n",
       "90957            144.0     10 TO 12      968000.0  6.130271e+05  354972.87500  \n",
       "90601            126.0     04 TO 06      935000.0  6.218501e+05  313149.87500  \n",
       "90382            121.0     10 TO 12      945000.0  6.372696e+05  307730.43750  \n",
       "92533            115.0     28 TO 30     1130000.0  8.252847e+05  304715.31250  \n",
       "90608            120.0     37 TO 39     1360000.0  1.067169e+06  292831.00000  \n",
       "92340            114.0     34 TO 36     1245000.0  9.555907e+05  289409.31250  \n",
       "91871             88.0     01 TO 03      680888.0  3.917240e+05  289163.96875  \n",
       "89770            126.0     10 TO 12      868000.0  5.796232e+05  288376.75000  \n",
       "92442            113.0     16 TO 18     1165000.0  8.769507e+05  288049.31250  \n",
       "92504             88.0     01 TO 03      695000.0  4.072437e+05  287756.31250  \n",
       "90600            121.0     07 TO 09      920000.0  6.324519e+05  287548.12500  \n",
       "88081            121.0     28 TO 30     1100000.0  8.136795e+05  286320.50000  \n",
       "92299             88.0     01 TO 03      690000.0  4.040589e+05  285941.06250  \n",
       "105702           148.0     10 TO 12     1235000.0  9.508851e+05  284114.87500  \n",
       "93895            139.0     07 TO 09      958000.0  6.745587e+05  283441.31250  \n",
       "93825            118.0     16 TO 18      938000.0  6.570492e+05  280950.75000  \n",
       "91694             88.0     01 TO 03      680000.0  4.008262e+05  279173.81250  \n",
       "100836           210.0     01 TO 03     1268000.0  9.892076e+05  278792.37500  \n",
       "112128           148.0     01 TO 03      998000.0  7.200508e+05  277949.25000  \n",
       "90521            121.0     07 TO 09      988000.0  7.135319e+05  274468.12500  \n",
       "101237           119.0     40 TO 42     1268000.0  9.967523e+05  271247.68750  \n",
       "90432            120.0     25 TO 27     1280000.0  1.009172e+06  270828.50000  \n",
       "92379             77.0     04 TO 06      640000.0  3.695614e+05  270438.62500  \n",
       "92066             77.0     01 TO 03      628000.0  3.577162e+05  270283.75000  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_df = df_test.copy()\n",
    "results_df['prediction'] = pred_df['resale_price_prediction']\n",
    "results_df['error'] = abs(results_df['resale_price'] - results_df['prediction'])\n",
    "\n",
    "top_errors = results_df.sort_values(by='error', ascending=False).head(25)\n",
    "display(top_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">08:05:22</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1575</span><span style=\"font-weight: bold\">}</span> - WARNING - Directory is not empty. Overwriting the \n",
       "contents.                                                                                                          \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m08:05:22\u001b[0m,\u001b[1;36m689\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1575\u001b[0m\u001b[1m}\u001b[0m - WARNING - Directory is not empty. Overwriting the \n",
       "contents.                                                                                                          \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tabular_model.save_model(\"models/b1_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part B, Q2 (10 marks)\n",
    "---\n",
    "In Question B1, we used the Category Embedding model. This creates a feedforward neural network in which the categorical features get learnable embeddings. In this question, we will make use of a library called Pytorch-WideDeep. This library makes it easy to work with multimodal deep-learning problems combining images, text, and tables. We will just be utilizing the deeptabular component of this library through the TabMlp network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install \"pytorch-widedeep==1.6.5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "import os\n",
    "\n",
    "import random\n",
    "random.seed(SEED)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "from pytorch_widedeep.preprocessing import TabPreprocessor\n",
    "from pytorch_widedeep.models import TabMlp, WideDeep\n",
    "from pytorch_widedeep import Trainer\n",
    "from pytorch_widedeep.metrics import R2Score\n",
    "\n",
    "from sklearn.metrics import r2_score, mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Divide the dataset (‘hdb_price_prediction.csv’) into train and test sets by using entries from the year 2020 and before as training data, and entries from 2021 and after as the test data（validation set is not required here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('hdb_price_prediction.csv')\n",
    "df_train = df[df['year'] <= 2020]\n",
    "df_test = df[df['year'] >= 2021]\n",
    "\n",
    "X_train = df_train.drop([\"resale_price\", \"year\"], axis=1)\n",
    "y_train = df_train[\"resale_price\"]\n",
    "X_test = df_test.drop([\"resale_price\", \"year\"], axis=1)\n",
    "y_test = df_test[\"resale_price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Refer to the documentation of Pytorch-WideDeep and perform the following tasks:\n",
    "https://pytorch-widedeep.readthedocs.io/en/latest/index.html\n",
    "* Use [**TabPreprocessor**](https://pytorch-widedeep.readthedocs.io/en/latest/examples/01_preprocessors_and_utils.html#2-tabpreprocessor) to create the deeptabular component using the continuous\n",
    "features and the categorical features. Use this component to transform the training dataset.\n",
    "* Create the [**TabMlp**](https://pytorch-widedeep.readthedocs.io/en/latest/pytorch-widedeep/model_components.html#pytorch_widedeep.models.tabular.mlp.tab_mlp.TabMlp) model with 2 hidden layers in the MLP, with 200 and 100 neurons respectively.\n",
    "* Create a [**Trainer**](https://pytorch-widedeep.readthedocs.io/en/latest/pytorch-widedeep/trainer.html#pytorch_widedeep.training.Trainer) for the training of the created TabMlp model with the root mean squared error (RMSE) cost function. Train the model for 60 epochs using this trainer, keeping a batch size of 64. (Note: set the *num_workers* parameter to 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuki/Library/Mobile Documents/com~apple~CloudDocs/NTU/Y2S2/SC4001/Projects/Assignment1/.venv/lib/python3.11/site-packages/pytorch_widedeep/preprocessing/tab_preprocessor.py:364: UserWarning: Continuous columns will not be normalised\n",
      "  warnings.warn(\"Continuous columns will not be normalised\")\n"
     ]
    }
   ],
   "source": [
    "continuous_cols=[\"dist_to_nearest_stn\", \"dist_to_dhoby\", \"degree_centrality\",\n",
    "                     \"eigenvector_centrality\", \"remaining_lease_years\", \"floor_area_sqm\"]\n",
    "categorical_cols=[\"month\", \"town\", \"flat_model_type\", \"storey_range\"]\n",
    "\n",
    "tab_preprocessor = TabPreprocessor(\n",
    "    cat_embed_cols=categorical_cols,\n",
    "    continuous_cols=continuous_cols\n",
    ")\n",
    "\n",
    "X_tab = tab_preprocessor.fit_transform(X_train)\n",
    "X_tab_test = tab_preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab_mlp = TabMlp(\n",
    "    column_idx=tab_preprocessor.column_idx,\n",
    "    cat_embed_input=tab_preprocessor.cat_embed_input,\n",
    "    continuous_cols=continuous_cols,\n",
    "    mlp_hidden_dims=[200, 100],\n",
    ")\n",
    "\n",
    "model = WideDeep(deeptabular=tab_mlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch 1: 100%|██████████| 1366/1366 [00:12<00:00, 111.37it/s, loss=1.83e+5, metrics={'r2': -1.2251}]\n",
      "epoch 2: 100%|██████████| 1366/1366 [00:11<00:00, 115.55it/s, loss=9.8e+4, metrics={'r2': 0.5041}] \n",
      "epoch 3: 100%|██████████| 1366/1366 [00:11<00:00, 119.00it/s, loss=7.72e+4, metrics={'r2': 0.703}] \n",
      "epoch 4: 100%|██████████| 1366/1366 [00:11<00:00, 116.60it/s, loss=6.55e+4, metrics={'r2': 0.8016}]\n",
      "epoch 5: 100%|██████████| 1366/1366 [00:11<00:00, 116.08it/s, loss=6.08e+4, metrics={'r2': 0.8327}]\n",
      "epoch 6: 100%|██████████| 1366/1366 [00:11<00:00, 117.64it/s, loss=5.9e+4, metrics={'r2': 0.8435}] \n",
      "epoch 7: 100%|██████████| 1366/1366 [00:11<00:00, 118.64it/s, loss=5.76e+4, metrics={'r2': 0.8509}]\n",
      "epoch 8: 100%|██████████| 1366/1366 [00:11<00:00, 119.80it/s, loss=5.69e+4, metrics={'r2': 0.8547}]\n",
      "epoch 9: 100%|██████████| 1366/1366 [00:11<00:00, 120.29it/s, loss=5.62e+4, metrics={'r2': 0.8584}]\n",
      "epoch 10: 100%|██████████| 1366/1366 [00:11<00:00, 119.35it/s, loss=5.52e+4, metrics={'r2': 0.8634}]\n",
      "epoch 11: 100%|██████████| 1366/1366 [00:11<00:00, 119.12it/s, loss=5.45e+4, metrics={'r2': 0.8669}]\n",
      "epoch 12: 100%|██████████| 1366/1366 [00:12<00:00, 112.36it/s, loss=5.36e+4, metrics={'r2': 0.8715}]\n",
      "epoch 13: 100%|██████████| 1366/1366 [00:11<00:00, 117.27it/s, loss=5.28e+4, metrics={'r2': 0.8753}]\n",
      "epoch 14: 100%|██████████| 1366/1366 [00:11<00:00, 118.10it/s, loss=5.22e+4, metrics={'r2': 0.8786}]\n",
      "epoch 15: 100%|██████████| 1366/1366 [00:11<00:00, 117.86it/s, loss=5.14e+4, metrics={'r2': 0.8819}]\n",
      "epoch 16: 100%|██████████| 1366/1366 [00:11<00:00, 116.74it/s, loss=5.08e+4, metrics={'r2': 0.8845}]\n",
      "epoch 17: 100%|██████████| 1366/1366 [00:11<00:00, 117.38it/s, loss=5.01e+4, metrics={'r2': 0.8883}]\n",
      "epoch 18: 100%|██████████| 1366/1366 [00:11<00:00, 119.24it/s, loss=4.97e+4, metrics={'r2': 0.8899}]\n",
      "epoch 19: 100%|██████████| 1366/1366 [00:11<00:00, 117.40it/s, loss=4.94e+4, metrics={'r2': 0.8912}]\n",
      "epoch 20: 100%|██████████| 1366/1366 [00:11<00:00, 118.05it/s, loss=4.9e+4, metrics={'r2': 0.8925}] \n",
      "epoch 21: 100%|██████████| 1366/1366 [00:12<00:00, 112.34it/s, loss=4.86e+4, metrics={'r2': 0.8945}]\n",
      "epoch 22: 100%|██████████| 1366/1366 [00:12<00:00, 109.93it/s, loss=4.85e+4, metrics={'r2': 0.895}] \n",
      "epoch 23: 100%|██████████| 1366/1366 [00:12<00:00, 110.37it/s, loss=4.83e+4, metrics={'r2': 0.8962}]\n",
      "epoch 24: 100%|██████████| 1366/1366 [00:11<00:00, 113.85it/s, loss=4.82e+4, metrics={'r2': 0.8965}]\n",
      "epoch 25: 100%|██████████| 1366/1366 [00:11<00:00, 115.13it/s, loss=4.8e+4, metrics={'r2': 0.8971}] \n",
      "epoch 26: 100%|██████████| 1366/1366 [00:12<00:00, 112.50it/s, loss=4.8e+4, metrics={'r2': 0.8971}] \n",
      "epoch 27: 100%|██████████| 1366/1366 [00:11<00:00, 115.08it/s, loss=4.78e+4, metrics={'r2': 0.898}] \n",
      "epoch 28: 100%|██████████| 1366/1366 [00:12<00:00, 113.22it/s, loss=4.8e+4, metrics={'r2': 0.8971}] \n",
      "epoch 29: 100%|██████████| 1366/1366 [00:12<00:00, 110.38it/s, loss=4.78e+4, metrics={'r2': 0.8983}]\n",
      "epoch 30: 100%|██████████| 1366/1366 [00:12<00:00, 110.69it/s, loss=4.76e+4, metrics={'r2': 0.8987}]\n",
      "epoch 31: 100%|██████████| 1366/1366 [00:12<00:00, 109.75it/s, loss=4.76e+4, metrics={'r2': 0.8989}]\n",
      "epoch 32: 100%|██████████| 1366/1366 [00:12<00:00, 111.12it/s, loss=4.74e+4, metrics={'r2': 0.8996}]\n",
      "epoch 33: 100%|██████████| 1366/1366 [00:11<00:00, 114.04it/s, loss=4.75e+4, metrics={'r2': 0.8992}]\n",
      "epoch 34: 100%|██████████| 1366/1366 [00:12<00:00, 113.34it/s, loss=4.74e+4, metrics={'r2': 0.8995}]\n",
      "epoch 35: 100%|██████████| 1366/1366 [00:11<00:00, 115.69it/s, loss=4.74e+4, metrics={'r2': 0.8996}]\n",
      "epoch 36: 100%|██████████| 1366/1366 [00:12<00:00, 113.01it/s, loss=4.72e+4, metrics={'r2': 0.9004}]\n",
      "epoch 37: 100%|██████████| 1366/1366 [00:12<00:00, 111.41it/s, loss=4.7e+4, metrics={'r2': 0.9011}] \n",
      "epoch 38: 100%|██████████| 1366/1366 [00:12<00:00, 111.36it/s, loss=4.71e+4, metrics={'r2': 0.9011}]\n",
      "epoch 39: 100%|██████████| 1366/1366 [00:11<00:00, 114.11it/s, loss=4.71e+4, metrics={'r2': 0.9006}]\n",
      "epoch 40: 100%|██████████| 1366/1366 [00:11<00:00, 115.00it/s, loss=4.69e+4, metrics={'r2': 0.9018}]\n",
      "epoch 41: 100%|██████████| 1366/1366 [00:12<00:00, 111.63it/s, loss=4.71e+4, metrics={'r2': 0.901}] \n",
      "epoch 42: 100%|██████████| 1366/1366 [00:12<00:00, 107.22it/s, loss=4.69e+4, metrics={'r2': 0.9018}]\n",
      "epoch 43: 100%|██████████| 1366/1366 [00:12<00:00, 113.34it/s, loss=4.67e+4, metrics={'r2': 0.9025}]\n",
      "epoch 44: 100%|██████████| 1366/1366 [00:12<00:00, 109.75it/s, loss=4.68e+4, metrics={'r2': 0.9021}]\n",
      "epoch 45: 100%|██████████| 1366/1366 [00:12<00:00, 108.74it/s, loss=4.68e+4, metrics={'r2': 0.902}] \n",
      "epoch 46: 100%|██████████| 1366/1366 [00:12<00:00, 109.77it/s, loss=4.69e+4, metrics={'r2': 0.9017}]\n",
      "epoch 47: 100%|██████████| 1366/1366 [00:12<00:00, 108.98it/s, loss=4.68e+4, metrics={'r2': 0.9022}]\n",
      "epoch 48: 100%|██████████| 1366/1366 [00:12<00:00, 109.33it/s, loss=4.69e+4, metrics={'r2': 0.9016}]\n",
      "epoch 49: 100%|██████████| 1366/1366 [00:12<00:00, 108.14it/s, loss=4.64e+4, metrics={'r2': 0.9038}]\n",
      "epoch 50: 100%|██████████| 1366/1366 [00:12<00:00, 106.72it/s, loss=4.65e+4, metrics={'r2': 0.9031}]\n",
      "epoch 51: 100%|██████████| 1366/1366 [00:12<00:00, 108.34it/s, loss=4.65e+4, metrics={'r2': 0.9035}]\n",
      "epoch 52: 100%|██████████| 1366/1366 [00:12<00:00, 109.86it/s, loss=4.66e+4, metrics={'r2': 0.9026}]\n",
      "epoch 53: 100%|██████████| 1366/1366 [00:11<00:00, 114.54it/s, loss=4.66e+4, metrics={'r2': 0.9028}]\n",
      "epoch 54: 100%|██████████| 1366/1366 [00:12<00:00, 109.74it/s, loss=4.65e+4, metrics={'r2': 0.9034}]\n",
      "epoch 55: 100%|██████████| 1366/1366 [00:12<00:00, 112.09it/s, loss=4.64e+4, metrics={'r2': 0.9035}]\n",
      "epoch 56: 100%|██████████| 1366/1366 [00:12<00:00, 108.62it/s, loss=4.63e+4, metrics={'r2': 0.9041}]\n",
      "epoch 57: 100%|██████████| 1366/1366 [00:12<00:00, 106.19it/s, loss=4.62e+4, metrics={'r2': 0.9043}]\n",
      "epoch 58: 100%|██████████| 1366/1366 [00:12<00:00, 106.98it/s, loss=4.63e+4, metrics={'r2': 0.9041}]\n",
      "epoch 59: 100%|██████████| 1366/1366 [00:12<00:00, 106.72it/s, loss=4.63e+4, metrics={'r2': 0.9042}]\n",
      "epoch 60: 100%|██████████| 1366/1366 [00:12<00:00, 105.78it/s, loss=4.62e+4, metrics={'r2': 0.9044}]\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(model, objective='rmse', metrics=[R2Score], num_workers=0)\n",
    "trainer.fit(X_tab=X_tab, target=y_train, n_epochs=60, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save(path='./models', model_filename='b2_model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">Report the test RMSE and the test R2 value that you obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "predict: 100%|██████████| 1128/1128 [00:03<00:00, 365.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  103412.90677234152\n",
      "R2:  0.6263645959243762\n"
     ]
    }
   ],
   "source": [
    "predictions = trainer.predict(X_tab=X_tab_test,batch_size=64)\n",
    "print(\"RMSE: \", np.sqrt(mean_squared_error(y_test, predictions)))\n",
    "print(\"R2: \", r2_score(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part B, Q3 (10 marks)\n",
    "---\n",
    "Besides ensuring that your neural network performs well, it is important to be able to explain the model’s decision. **Captum** is a very handy library that helps you to do so for PyTorch models.\n",
    "\n",
    "Many model explainability algorithms for deep learning models are available in Captum. These algorithms are often used to generate an attribution score for each feature. Features with larger scores are more ‘important’ and some algorithms also provide information about directionality (i.e. a feature with very negative attribution scores means the larger the value of that feature, the lower the value of the output).\n",
    "\n",
    "In general, these algorithms can be grouped into two paradigms:\n",
    "- **perturbation based approaches** (e.g. Feature Ablation)\n",
    "- **gradient / backpropagation based approaches** (e.g. Saliency)\n",
    "\n",
    "The former adopts a brute-force approach of removing / permuting features one by one and does not scale up well. The latter depends on gradients and they can be computed relatively quickly. But unlike how backpropagation computes gradients with respect to weights, gradients here are computed **with respect to the input**. This gives us a sense of how much a change in the input affects the model’s outputs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install \"captum\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "import os\n",
    "\n",
    "import random\n",
    "random.seed(SEED)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "from captum.attr import DeepLift, InputXGradient, IntegratedGradients, GradientShap, FeatureAblation\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from os import path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> First, use the train set (year 2020 and before) and test set (year 2021) following the splits in Question B1 (validation set is not required here). To keep things simple, we will **limit our analysis to numeric / continuous features only**. Drop all categorical features from the dataframes. Standardise the features via **StandardScaler** (fit to training set, then transform all)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 1000\n",
    "target = ['resale_price']\n",
    "n_epochs = 60\n",
    "batch_size = 64\n",
    "lr = 0.001\n",
    "hidden_neuron = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('hdb_price_prediction.csv')\n",
    "continuous_cols=[\"dist_to_nearest_stn\", \"dist_to_dhoby\", \"degree_centrality\",\n",
    "                     \"eigenvector_centrality\", \"remaining_lease_years\", \"floor_area_sqm\"]\n",
    "categorical_cols=[\"month\", \"year\", \"town\", \"full_address\", \"nearest_stn\",  \"flat_model_type\", \"storey_range\"]\n",
    "\n",
    "df_train = df[df['year'] <= 2020]\n",
    "df_test = df[df['year'] == 2021]\n",
    "\n",
    "df_train = df.drop(categorical_cols, axis=1)\n",
    "df_test = df.drop(categorical_cols, axis=1)\n",
    "\n",
    "X_train = df_train.drop(\"resale_price\", axis=1)\n",
    "y_train = df_train[\"resale_price\"]\n",
    "X_test = df_test.drop(\"resale_price\", axis=1)\n",
    "y_test = df_test[\"resale_price\"]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Follow this tutorial to generate the plot from various model explainability algorithms (https://captum.ai/tutorials/House_Prices_Regression_Interpret).\n",
    "Specifically, make the following changes:\n",
    "- Use a feedforward neural network with 3 hidden layers, each having 5 neurons. Train using Adam optimiser with learning rate of 0.001.\n",
    "- Use Input x Gradients, Integrated Gradients, DeepLift, GradientSHAP, Feature Ablation. To avoid long running time, you can limit the analysis to the first 1000 samples in test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled = torch.tensor(X_train_scaled, dtype=torch.float)\n",
    "y_train = torch.tensor(y_train.values, dtype=torch.float).view(-1, 1)\n",
    "\n",
    "X_test_scaled = torch.tensor(X_test_scaled, dtype=torch.float)\n",
    "y_test = torch.tensor(y_test.values, dtype=torch.float).view(-1, 1)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_scaled, y_train)\n",
    "test_dataset = TensorDataset(X_test_scaled, y_test)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b3_model(\n",
       "  (lin1): Linear(in_features=6, out_features=5, bias=True)\n",
       "  (relu1): ReLU()\n",
       "  (lin2): Linear(in_features=5, out_features=5, bias=True)\n",
       "  (relu2): ReLU()\n",
       "  (lin3): Linear(in_features=5, out_features=5, bias=True)\n",
       "  (relu3): ReLU()\n",
       "  (lin4): Linear(in_features=5, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class b3_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(6, hidden_neuron)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.lin2 = nn.Linear(hidden_neuron, hidden_neuron)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.lin3 = nn.Linear(hidden_neuron, hidden_neuron)\n",
    "        self.relu3 = nn.ReLU()\n",
    "        self.lin4 = nn.Linear(hidden_neuron, 1)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        return self.lin4(self.relu3(self.lin3(self.relu2(self.lin2(self.relu1(self.lin1(input)))))))\n",
    "    \n",
    "model = b3_model()\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "def train(model_inp, optimizer=optimizer, num_epochs=n_epochs):\n",
    "    for epoch in range(num_epochs):  # loop over the dataset multiple times\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_dataloader:\n",
    "            # forward pass\n",
    "            outputs = model_inp(inputs)\n",
    "            # defining loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            # computing gradients\n",
    "            loss.backward()\n",
    "            # accumulating running loss\n",
    "            running_loss += loss.item()\n",
    "            # updated weights based on computed gradients\n",
    "            optimizer.step()\n",
    "        if epoch % 20 == 0:    \n",
    "            print('Epoch [%d]/[%d] running accumulative loss across all batches: %.3f' %\n",
    "                  (epoch + 1, num_epochs, running_loss))\n",
    "        running_loss = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pre-trained model from: models/b3_model\n"
     ]
    }
   ],
   "source": [
    "def train_load_save_model(model_obj, model_path):\n",
    "    if path.isfile(model_path):\n",
    "        print('Loading pre-trained model from: {}'.format(model_path))\n",
    "        model_obj.load_state_dict(torch.load(model_path))\n",
    "    else:    \n",
    "        train(model_obj)\n",
    "        print('Finished training the model. Saving the model to the path: {}'.format(model_path))\n",
    "        torch.save(model_obj.state_dict(), model_path)\n",
    "\n",
    "SAVED_MODEL_PATH = 'models/b3_model'\n",
    "train_load_save_model(model, SAVED_MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE:  79066.96220293277\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "outputs = model(X_test_scaled)\n",
    "err = np.sqrt(mean_squared_error(outputs.detach().numpy(), y_test.detach().numpy()))\n",
    "\n",
    "print('RMSE: ', err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuki/Library/Mobile Documents/com~apple~CloudDocs/NTU/Y2S2/SC4001/Projects/Assignment1/.venv/lib/python3.11/site-packages/captum/_utils/gradient.py:57: UserWarning: Input Tensor 0 did not already require gradients, required_grads has been set automatically.\n",
      "  warnings.warn(\n",
      "/Users/yuki/Library/Mobile Documents/com~apple~CloudDocs/NTU/Y2S2/SC4001/Projects/Assignment1/.venv/lib/python3.11/site-packages/captum/attr/_core/deep_lift.py:304: UserWarning: Setting forward, backward hooks and attributes on non-linear\n",
      "               activations. The hooks and attributes will be removed\n",
      "            after the attribution is finished\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "dl = DeepLift(model)\n",
    "ixg = InputXGradient(model)\n",
    "ig = IntegratedGradients(model)\n",
    "gs = GradientShap(model)\n",
    "fa = FeatureAblation(model)\n",
    "\n",
    "shortened_X_test = X_test_scaled[:n]\n",
    "\n",
    "dl_attr_test = dl.attribute(shortened_X_test)\n",
    "ixg_attr_test = ixg.attribute(shortened_X_test)\n",
    "ig_attr_test = ig.attribute(shortened_X_test, n_steps=50)\n",
    "gs_attr_test = gs.attribute(shortened_X_test, X_train_scaled)\n",
    "fa_attr_test = fa.attribute(shortened_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_axis_data = np.arange(X_test_scaled.shape[1])\n",
    "x_axis_data_labels = list(map(lambda idx: continuous_cols[idx], x_axis_data))\n",
    "\n",
    "dl_attr_test_sum = dl_attr_test.detach().numpy().sum(0)\n",
    "dl_attr_test_norm_sum = dl_attr_test_sum / np.linalg.norm(dl_attr_test_sum, ord=1)\n",
    "\n",
    "ixg_attr_test_sum = ixg_attr_test.detach().numpy().sum(0)\n",
    "ixg_attr_test_norm_sum = ixg_attr_test_sum / np.linalg.norm(ixg_attr_test_sum, ord=1)\n",
    "\n",
    "ig_attr_test_sum = ig_attr_test.detach().numpy().sum(0)\n",
    "ig_attr_test_norm_sum = ig_attr_test_sum / np.linalg.norm(ig_attr_test_sum, ord=1)\n",
    "\n",
    "gs_attr_test_sum = gs_attr_test.detach().numpy().sum(0)\n",
    "gs_attr_test_norm_sum = gs_attr_test_sum / np.linalg.norm(gs_attr_test_sum, ord=1)\n",
    "\n",
    "fa_attr_test_sum = fa_attr_test.detach().numpy().sum(0)\n",
    "fa_attr_test_norm_sum = fa_attr_test_sum / np.linalg.norm(fa_attr_test_sum, ord=1)\n",
    "\n",
    "width = 0.14\n",
    "legends = ['DeepLift','Input x Gradients', 'Integrated Gradients', 'GradientSHAP', 'Feature Ablation']\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "\n",
    "ax = plt.subplot()\n",
    "ax.set_title('Comparing input feature importances across multiple algorithms and learned weights')\n",
    "ax.set_ylabel('Attributions')\n",
    "\n",
    "FONT_SIZE = 16\n",
    "plt.rc('font', size=FONT_SIZE)\n",
    "plt.rc('axes', titlesize=FONT_SIZE)\n",
    "plt.rc('axes', labelsize=FONT_SIZE)\n",
    "plt.rc('legend', fontsize=FONT_SIZE - 4)\n",
    "\n",
    "ax.bar(x_axis_data, dl_attr_test_norm_sum, width, align='center', alpha=0.8, color='#f5a142')\n",
    "ax.bar(x_axis_data + width, ixg_attr_test_norm_sum, width, align='center', alpha=0.8, color='#f5428d')\n",
    "ax.bar(x_axis_data + 2 * width, ig_attr_test_norm_sum, width, align='center', alpha=0.8, color='#eb5e7c')\n",
    "ax.bar(x_axis_data + 3 * width, gs_attr_test_norm_sum, width, align='center',  alpha=0.8, color='#4260f5')\n",
    "ax.bar(x_axis_data + 4 * width, fa_attr_test_norm_sum, width, align='center', alpha=1.0, color='#49ba81')\n",
    "\n",
    "ax.autoscale_view()\n",
    "plt.tight_layout()\n",
    "\n",
    "ax.set_xticks(x_axis_data + 0.5)\n",
    "ax.set_xticklabels(x_axis_data_labels)\n",
    "\n",
    "plt.legend(legends, loc=3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Read the following [descriptions](https://captum.ai/docs/attribution_algorithms) and [comparisons](https://captum.ai/docs/algorithms_comparison_matrix) in Captum to build up your understanding of the difference of various explainability algorithms. Based on your plot, identify the three most important features for regression. Explain how each of these features influences the regression outcome.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graph above, we can see that the three most important features are\n",
    "1. Eigenvector Centrality\n",
    "2. Remaining Lease Year\n",
    "3. Floor Area Sqm.\n",
    "\n",
    "We choose these three features as the graph shows greater attribution in all of the algorithms.\n",
    "\n",
    "It is agreed by almost all algorithms, that eigenvector centrality and floor area size contributes negatively to resale price (i.e. as floor area size increases, the resale price decreases). Meanwhile, remaining lease year contributes positively to resale price (i.e. as remaining lease year increases, resale price increases).\n",
    "\n",
    "While the positive relationship between remaining lease year and resale price is expected, the reason why the other two are not is due to the small test sample. As such, the test is not as robust, and can only be used as a preliminary / sanity check."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part B, Q4 (10 marks)\n",
    "---\n",
    "\n",
    "Model degradation is a common issue faced when deploying machine learning models (including neural networks) in the real world. New data points could exhibit a different pattern from older data points due to factors such as changes in government policy or market sentiments. For instance, housing prices in Singapore have been increasing and the Singapore government has introduced 3 rounds of cooling measures over the past years (16 December 2021, 30 September 2022, 27 April 2023).\n",
    "\n",
    "In such situations, the distribution of the new data points could differ from the original data distribution which the models were trained on. Recall that machine learning models often work with the assumption that the test distribution should be similar to train distribution. When this assumption is violated, model performance will be adversely impacted.  In the last part of this assignment, we will investigate to what extent model degradation has occurred.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install \"alibi-detect\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "\n",
    "import os\n",
    "\n",
    "import random\n",
    "random.seed(SEED)\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(SEED)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from pytorch_tabular import TabularModel\n",
    "from pytorch_tabular.models import CategoryEmbeddingModelConfig\n",
    "from pytorch_tabular.config import (\n",
    "    DataConfig,\n",
    "    OptimizerConfig,\n",
    "    TrainerConfig,\n",
    ")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)\n",
    "\n",
    "from alibi_detect.cd import TabularDrift"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Evaluate your model from B1 on data from year 2022 and report the test R2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:30:16</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">113</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">171</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m15:30:16\u001b[0m,\u001b[1;36m113\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m171\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:30:16</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">115</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m15:30:16\u001b[0m,\u001b[1;36m115\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Trainer already configured with model summary callbacks: [<class 'pytorch_lightning.callbacks.rich_model_summary.RichModelSummary'>]. Skipping setting a default `ModelSummary` callback.\n",
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b68b19c3ea184952afe829eb7f00be90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuki/Library/Mobile Documents/com~apple~CloudDocs/NTU/Y2S2/SC4001/Projects/Assignment1/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       13622424576.0       </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test_mean_squared_error  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       13622424576.0       </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_r2_score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.5126631259918213     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      13622424576.0      \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m test_mean_squared_error \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      13622424576.0      \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_r2_score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.5126631259918213    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 116715\n",
      "R2 score: 0.5127\n"
     ]
    }
   ],
   "source": [
    "b1_model = TabularModel.load_model(\"models/b1_model\")\n",
    "\n",
    "df = pd.read_csv('hdb_price_prediction.csv')\n",
    "df_test = df[df[\"year\"] == 2022]\n",
    "\n",
    "pred = b1_model.predict(df_test)\n",
    "test_results = b1_model.evaluate(df_test)\n",
    "print(f\"RMSE: {np.sqrt(test_results[0]['test_mean_squared_error']):.0f}\")\n",
    "print(f\"R2 score: {test_results[0]['test_r2_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Evaluate your model from B1 on data from year 2023 and report the test R2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba4b3e53dcc14d6f9b2ff22154e03e64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuki/Library/Mobile Documents/com~apple~CloudDocs/NTU/Y2S2/SC4001/Projects/Assignment1/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'test_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       21857935360.0       </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test_mean_squared_error  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       21857935360.0       </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_r2_score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.2336064875125885     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      21857935360.0      \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m test_mean_squared_error \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      21857935360.0      \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_r2_score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.2336064875125885    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 147844\n",
      "R2 score: 0.2336\n"
     ]
    }
   ],
   "source": [
    "df_test = df[df[\"year\"] == 2023]\n",
    "\n",
    "pred = b1_model.predict(df_test)\n",
    "test_results = b1_model.evaluate(df_test)\n",
    "print(f\"RMSE: {np.sqrt(test_results[0]['test_mean_squared_error']):.0f}\")\n",
    "print(f\"R2 score: {test_results[0]['test_r2_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Did model degradation occur for the deep learning model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing the model performance between the two years, we can see that RMSE increases (from 116715 to 147844) and R2 score decrases (from 0.5127 to 0.2336). This shows model degradation occured."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model degradation could be caused by [various data distribution shifts](https://huyenchip.com/2022/02/07/data-distribution-shifts-and-monitoring.html#data-shift-types): covariate shift (features), label shift and/or concept drift (altered relationship between features and labels).\n",
    "There are various conflicting terminologies in the [literature](https://www.sciencedirect.com/science/article/pii/S0950705122002854#tbl1). Let’s stick to this reference for this assignment.\n",
    "\n",
    "> Using the **Alibi Detect** library, apply the **TabularDrift** function with the training data (year 2020 and before) used as the reference and **detect which features have drifted** in the 2023 test dataset. Before running the statistical tests, ensure you **sample 1000 data points** each from the train and test data. Do not use the whole train/test data. (Hint: use this example as a guide https://docs.seldon.io/projects/alibi-detect/en/stable/examples/cd_chi2ks_adult.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('hdb_price_prediction.csv')\n",
    "columns_to_drop = ['full_address', 'nearest_stn', 'year', 'resale_price']\n",
    "categorical_cols=[\"month\", \"town\", \"flat_model_type\", \"storey_range\"]\n",
    "\n",
    "n_ref = 1000\n",
    "n_test = 1000\n",
    "\n",
    "df_train = df[df[\"year\"] <= 2020]\n",
    "df_train = df_train.sample(n=n_ref, random_state=SEED)  \n",
    "\n",
    "df_test = df[df[\"year\"] == 2023]\n",
    "df_test = df_test.sample(n=n_test, random_state=SEED)\n",
    "\n",
    "df_train.drop(columns_to_drop, axis=1, inplace=True)\n",
    "df_test.drop(columns_to_drop, axis=1, inplace=True)\n",
    "\n",
    "X_ref = df_train.values\n",
    "X_test = df_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: None, 1: None, 6: None, 9: None}\n"
     ]
    }
   ],
   "source": [
    "categorical_indices = [df_train.columns.get_loc(col) for col in categorical_cols]\n",
    "categories_per_feature={idx: None for idx in categorical_indices} \n",
    "print(categories_per_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>p-Value</th>\n",
       "      <th>Drift?</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>month</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>town</td>\n",
       "      <td>0.996818</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dist_to_nearest_stn</td>\n",
       "      <td>0.010646</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>dist_to_dhoby</td>\n",
       "      <td>0.747317</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>degree_centrality</td>\n",
       "      <td>0.849408</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>eigenvector_centrality</td>\n",
       "      <td>0.635238</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>flat_model_type</td>\n",
       "      <td>0.139029</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>remaining_lease_years</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>floor_area_sqm</td>\n",
       "      <td>0.104391</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>storey_range</td>\n",
       "      <td>0.030843</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Feature   p-Value  Drift?\n",
       "0                   month  0.000000    True\n",
       "1                    town  0.996818   False\n",
       "2     dist_to_nearest_stn  0.010646   False\n",
       "3           dist_to_dhoby  0.747317   False\n",
       "4       degree_centrality  0.849408   False\n",
       "5  eigenvector_centrality  0.635238   False\n",
       "6         flat_model_type  0.139029   False\n",
       "7   remaining_lease_years  0.000002    True\n",
       "8          floor_area_sqm  0.104391   False\n",
       "9            storey_range  0.030843   False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "categorical_indices = [df_train.columns.get_loc(col) for col in categorical_cols]\n",
    "categories_per_feature={idx: None for idx in categorical_indices} \n",
    "\n",
    "cd = TabularDrift(X_ref, p_val=.05, categories_per_feature=categories_per_feature)\n",
    "\n",
    "preds = cd.predict(X_test)\n",
    "\n",
    "drift_results = pd.DataFrame({\n",
    "    \"Feature\": df_train.columns,\n",
    "    \"p-Value\": preds[\"data\"][\"p_val\"],\n",
    "    \"Drift?\": preds[\"data\"][\"p_val\"] < preds[\"data\"][\"threshold\"]\n",
    "})\n",
    "\n",
    "display(drift_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Assuming that the flurry of housing measures have made an impact on the relationship between all the features and resale_price (i.e. P(Y|X) changes), which type of data distribution shift possibly led to model degradation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on [this website](https://huyenchip.com/2022/02/07/data-distribution-shifts-and-monitoring.html#data-shift-types), if the relationship between all features and resale_price changes, **concept drift** occurred. This suggests that the initial distribution is outdated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> From your analysis via TabularDrift, which features contribute to this shift?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the table, we can see that the two features that contributes to the drift are\n",
    "1. Month of transaction\n",
    "2. Remaining lease year"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Suggest 1 way to address model degradation and implement it, showing improved test R2 for year 2023."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we want to test for resale_price in 2023, we can improve on the model by training it on the year 2022 instead. \n",
    "\n",
    "**Training data: 2022\\\n",
    "Test data: 2023**\n",
    "\n",
    "This ensures that our model is not outdated, as a more recent pricing reflects the current state of the market better, resulting in better predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:30:51</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">523</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">146</span><span style=\"font-weight: bold\">}</span> - INFO - Experiment Tracking is turned off           \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m15:30:51\u001b[0m,\u001b[1;36m523\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m146\u001b[0m\u001b[1m}\u001b[0m - INFO - Experiment Tracking is turned off           \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:30:51</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">538</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">548</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the DataLoaders                   \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m15:30:51\u001b[0m,\u001b[1;36m538\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m548\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the DataLoaders                   \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:30:51</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">549</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_datamodul<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">e:522</span><span style=\"font-weight: bold\">}</span> - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m15:30:51\u001b[0m,\u001b[1;36m549\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_datamodul\u001b[1;92me:522\u001b[0m\u001b[1m}\u001b[0m - INFO - Setting up the datamodule for          \n",
       "regression task                                                                                                    \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:30:51</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">582</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">599</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Model: CategoryEmbeddingModel \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m15:30:51\u001b[0m,\u001b[1;36m582\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m599\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Model: CategoryEmbeddingModel \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:30:51</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">603</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">342</span><span style=\"font-weight: bold\">}</span> - INFO - Preparing the Trainer                       \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m15:30:51\u001b[0m,\u001b[1;36m603\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m342\u001b[0m\u001b[1m}\u001b[0m - INFO - Preparing the Trainer                       \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:30:51</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">617</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">656</span><span style=\"font-weight: bold\">}</span> - INFO - Auto LR Find Started                        \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m15:30:51\u001b[0m,\u001b[1;36m617\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m656\u001b[0m\u001b[1m}\u001b[0m - INFO - Auto LR Find Started                        \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuki/Library/Mobile Documents/com~apple~CloudDocs/NTU/Y2S2/SC4001/Projects/Assignment1/.venv/lib/python3.11/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /Users/yuki/Library/Mobile Documents/com~apple~CloudDocs/NTU/Y2S2/SC4001/Projects/Assignment1/saved_models exists and is not empty.\n",
      "/Users/yuki/Library/Mobile Documents/com~apple~CloudDocs/NTU/Y2S2/SC4001/Projects/Assignment1/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n",
      "/Users/yuki/Library/Mobile Documents/com~apple~CloudDocs/NTU/Y2S2/SC4001/Projects/Assignment1/.venv/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (21) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n",
      "/Users/yuki/Library/Mobile Documents/com~apple~CloudDocs/NTU/Y2S2/SC4001/Projects/Assignment1/.venv/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'val_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=9` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8500897d64ce40c8a9db4a15d5bf614d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Finding best initial lr:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_steps=100` reached.\n",
      "Learning rate set to 0.8317637711026709\n",
      "Restoring states from the checkpoint path at /Users/yuki/Library/Mobile Documents/com~apple~CloudDocs/NTU/Y2S2/SC4001/Projects/Assignment1/.lr_find_0ce255d6-6f24-4baa-a24e-a2621e5069c6.ckpt\n",
      "Restored all states from the checkpoint at /Users/yuki/Library/Mobile Documents/com~apple~CloudDocs/NTU/Y2S2/SC4001/Projects/Assignment1/.lr_find_0ce255d6-6f24-4baa-a24e-a2621e5069c6.ckpt\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:30:56</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">161</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">669</span><span style=\"font-weight: bold\">}</span> - INFO - Suggested LR: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8317637711026709</span>. For plot  \n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m15:30:56\u001b[0m,\u001b[1;36m161\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m669\u001b[0m\u001b[1m}\u001b[0m - INFO - Suggested LR: \u001b[1;36m0.8317637711026709\u001b[0m. For plot  \n",
       "and detailed analysis, use `find_learning_rate` method.                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:30:56</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">162</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">678</span><span style=\"font-weight: bold\">}</span> - INFO - Training Started                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m15:30:56\u001b[0m,\u001b[1;36m162\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m678\u001b[0m\u001b[1m}\u001b[0m - INFO - Training Started                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name             </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type                      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Mode  </span>┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ _backbone        │ CategoryEmbeddingBackbone │  3.0 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ _embedding_layer │ Embedding1dLayer          │  1.6 K │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 2 </span>│ head             │ LinearHead                │     51 │ train │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 3 </span>│ loss             │ MSELoss                   │      0 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┳━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName            \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType                     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mMode \u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━╇━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ _backbone        │ CategoryEmbeddingBackbone │  3.0 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ _embedding_layer │ Embedding1dLayer          │  1.6 K │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m2\u001b[0m\u001b[2m \u001b[0m│ head             │ LinearHead                │     51 │ train │\n",
       "│\u001b[2m \u001b[0m\u001b[2m3\u001b[0m\u001b[2m \u001b[0m│ loss             │ MSELoss                   │      0 │ train │\n",
       "└───┴──────────────────┴───────────────────────────┴────────┴───────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 4.6 K                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 4.6 K                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 0                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in train mode</span>: 16                                                                                          \n",
       "<span style=\"font-weight: bold\">Modules in eval mode</span>: 0                                                                                            \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 4.6 K                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 4.6 K                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 0                                                                          \n",
       "\u001b[1mModules in train mode\u001b[0m: 16                                                                                          \n",
       "\u001b[1mModules in eval mode\u001b[0m: 0                                                                                            \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc35b97b8cf345f6ae8797f1dbca3e4d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:31:07</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">762</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">689</span><span style=\"font-weight: bold\">}</span> - INFO - Training the model completed                \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m15:31:07\u001b[0m,\u001b[1;36m762\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m689\u001b[0m\u001b[1m}\u001b[0m - INFO - Training the model completed                \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2025</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">03</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-weight: bold\">15:31:07</span>,<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">764</span> - <span style=\"font-weight: bold\">{</span>pytorch_tabular.tabular_model:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1529</span><span style=\"font-weight: bold\">}</span> - INFO - Loading the best model                     \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;36m2025\u001b[0m-\u001b[1;36m03\u001b[0m-\u001b[1;36m14\u001b[0m \u001b[1;92m15:31:07\u001b[0m,\u001b[1;36m764\u001b[0m - \u001b[1m{\u001b[0mpytorch_tabular.tabular_model:\u001b[1;36m1529\u001b[0m\u001b[1m}\u001b[0m - INFO - Loading the best model                     \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53c9d1e438cc42f9ba611c0fe339a6e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         test_loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       3033301504.0        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">  test_mean_squared_error  </span>│<span style=\"color: #800080; text-decoration-color: #800080\">       3033301504.0        </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">       test_r2_score       </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.8951436877250671     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        test_loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      3033301504.0       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m test_mean_squared_error \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m      3033301504.0       \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m      test_r2_score      \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.8951436877250671    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 55075\n",
      "R2 score: 0.8951\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('hdb_price_prediction.csv')\n",
    "df_train = df[df['year'] == 2022]\n",
    "df_test = df[df['year'] == 2023] \n",
    "\n",
    "data_config = DataConfig(\n",
    "    target=[\"resale_price\"],\n",
    "    continuous_cols=[\"dist_to_nearest_stn\", \"dist_to_dhoby\", \"degree_centrality\",\n",
    "                     \"eigenvector_centrality\", \"remaining_lease_years\", \"floor_area_sqm\"],\n",
    "    categorical_cols=[\"month\", \"town\", \"flat_model_type\", \"storey_range\"]\n",
    ")\n",
    "\n",
    "trainer_config = TrainerConfig(batch_size=1024, max_epochs=50, accelerator=\"auto\", auto_lr_find=True)\n",
    "model_config = CategoryEmbeddingModelConfig(task=\"regression\", layers='50', seed=SEED, metrics=['mean_squared_error','r2_score'])\n",
    "optimizer_config = OptimizerConfig(optimizer='Adam')\n",
    "\n",
    "tabular_model = TabularModel(\n",
    "    data_config=data_config,\n",
    "    model_config=model_config,\n",
    "    optimizer_config=optimizer_config,\n",
    "    trainer_config=trainer_config,\n",
    ")\n",
    "\n",
    "tabular_model.fit(train=df_train)\n",
    "test_results = tabular_model.evaluate(df_test)\n",
    "print(f\"RMSE: {np.sqrt(test_results[0]['test_mean_squared_error']):.0f}\")\n",
    "print(f\"R2 score: {test_results[0]['test_r2_score']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the R2 score for 2023 improved to 0.89. This suggests that training on 2022 data is a good way to predict 2023 resale prices."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOG8ZhA98h3O6fnefkjOU9w",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
